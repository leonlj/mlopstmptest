{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment with parameters for a Ridge Regression Model on the Diabetes Dataset in an Azure ML Pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is for experimenting with different parameters to train a ridge regression model on the Diabetes dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import tempfile\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment, Datastore\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.34.0\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1669875172712
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.pipeline.core.graph import PipelineParameter\n",
        "\n",
        "print(\"Pipeline SDK-specific imports completed\")\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline SDK-specific imports completed\nleonamltestcn\nleonamljci\nchinaeast2\nf7ccde76-13d3-4104-a67c-a396e59e872b\n"
        }
      ],
      "execution_count": 105,
      "metadata": {
        "gather": {
          "logged": 1669945665759
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "model_register_folder = 'model'\n",
        "os.makedirs(model_register_folder, exist_ok=True)\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1669875190677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define data transfer folder between different steps\r\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\r\n",
        "model_folder = PipelineData(\"model_release_folder\", datastore=ws.get_default_datastore())"
      ],
      "outputs": [],
      "execution_count": 111,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669948450030
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Pipeline step execution script"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $model_register_folder/prepare.py\r\n",
        "from azureml.core import Run\r\n",
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "import json\r\n",
        "import urllib.request\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"model\", help='output folder')\r\n",
        "parser.add_argument(\"--pipeline_param\", type=str, help=\"pipeline parameter\")\r\n",
        "\r\n",
        "args = parser.parse_args()\r\n",
        "output_folder = args.output_folder\r\n",
        "\r\n",
        "#  Get input model release config file\r\n",
        "print(\"pipeline Argument :\" + args.pipeline_param)\r\n",
        "config_file = args.pipeline_param\r\n",
        "\r\n",
        "# Save the parameters, model, score, cona etc. files to the outputs folder\r\n",
        "os.makedirs(output_folder, exist_ok=True)\r\n",
        "print(\"%s created\" % args.output_folder)\r\n",
        "\r\n",
        "# Create a folder for the model release files\r\n",
        "model_register_folder = 'model'\r\n",
        "os.makedirs(model_register_folder, exist_ok=True)\r\n",
        "\r\n",
        "urllib.request.urlretrieve(config_file, \"model/parameters.json\")\r\n",
        "\r\n",
        "with open(\"model/parameters.json\") as f:\r\n",
        "        pars = json.load(f)\r\n",
        "try:\r\n",
        "    register_args_model = pars[\"model\"]\r\n",
        "    print(register_args_model)\r\n",
        "except KeyError:\r\n",
        "    print(\"Could not load registration values from file\")\r\n",
        "    register_args_model =\"\"\r\n",
        "\r\n",
        "try:\r\n",
        "    register_args_score = pars[\"scoring\"]\r\n",
        "    print(register_args_score)\r\n",
        "except KeyError:\r\n",
        "    print(\"Could not load registration values from file\")\r\n",
        "    register_args_score =\"\"\r\n",
        "\r\n",
        "try:\r\n",
        "    register_args_conda = pars[\"conda\"]\r\n",
        "    print(register_args_conda)\r\n",
        "except KeyError:\r\n",
        "    print(\"Could not load registration values from file\")\r\n",
        "    register_args_conda =\"\"\r\n",
        "\r\n",
        "try:\r\n",
        "    register_args_modelname = pars[\"modelname\"]\r\n",
        "    print(register_args_modelname)\r\n",
        "except KeyError:\r\n",
        "    print(\"Could not load registration values from file\")\r\n",
        "    register_args_modelname = \"model.pkl\"\r\n",
        "\r\n",
        "urllib.request.urlretrieve(register_args_model, \"model/\"+ register_args_modelname)\r\n",
        "\r\n",
        "urllib.request.urlretrieve(register_args_conda, os.path.join(model_register_folder, 'conda_dependencies.yml'))\r\n",
        "\r\n",
        "urllib.request.urlretrieve(register_args_score, os.path.join(model_register_folder, 'score.py'))\r\n",
        "\r\n",
        "\r\n",
        "#list all file in model and all file in output_folder\r\n",
        "local_dir_list = os.listdir(model_register_folder)\r\n",
        " \r\n",
        "print(\"Files and directories in '\", model_register_folder, \"' :\")\r\n",
        " \r\n",
        "# prints all files\r\n",
        "print(local_dir_list)\r\n",
        "\r\n",
        "\r\n",
        "print(\"saving model release files\")\r\n",
        "#shutil.copytree(model_register_folder, output_folder)\r\n",
        "\r\n",
        "# iterating over all the files in\r\n",
        "# the source directory\r\n",
        "for fname in local_dir_list:\r\n",
        "     \r\n",
        "    # copying the files to the\r\n",
        "    # destination directory\r\n",
        "    shutil.copy2(os.path.join(model_register_folder,fname), output_folder)\r\n",
        "\r\n",
        "#list all file in output_folder\r\n",
        "dir_list = os.listdir(output_folder)\r\n",
        " \r\n",
        "print(\"Files and directories in '\", output_folder, \"' :\")\r\n",
        " \r\n",
        "# prints all files\r\n",
        "print(dir_list)\r\n",
        "\r\n",
        "print(\"delete temp model folder\")\r\n",
        "#shutil.rmtree(model_register_folder)\r\n",
        "\r\n",
        "print(\"model release files saved.....\" + output_folder)\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model/prepare.py\n"
        }
      ],
      "execution_count": 110,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $model_register_folder/register_deploy.py\n",
        "# Import libraries\n",
        "import argparse\n",
        "import joblib\n",
        "import sklearn\n",
        "from azureml.core import Workspace, Model, Run\n",
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"model\", help='model location')\n",
        "args = parser.parse_args()\n",
        "model_folder = args.model_folder\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the model release files\n",
        "model_file = model_folder + \"/sklearn_regression_model.pkl\"\n",
        "conda_file = model_folder + \"/conda_dependencies.yml\"\n",
        "score_file = model_folder + \"/score.py\"\n",
        "\n",
        "#model_file = \"sklearn_regression_model.pkl\"\n",
        "#conda_file = \"conda_dependencies.yml\"\n",
        "#score_file = \"score.py\"\n",
        "\n",
        "print(\"Loading model: \" + model_file)\n",
        "print(\"Loading conda: \" + conda_file)\n",
        "print(\"Loading score: \" + score_file)\n",
        "\n",
        "fileconent = open(conda_file, \"r\").read()\n",
        "print(\"show yml: \\n\" + fileconent)\n",
        "\n",
        "model = joblib.load(model_file)\n",
        "\n",
        "model_deployed = Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'test_sklearn_model_pipeline',\n",
        "               tags={'Training context':'Pipeline'})\n",
        "\n",
        "#Deploy to ACI test\n",
        "\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "\n",
        "service_name = 'mytestpipelinesrv3'\n",
        "\n",
        "environment = Environment.from_conda_specification(name=\"myenv\", file_path=conda_file)\n",
        "\n",
        "#environment = Environment('my-sklearn-environment2')\n",
        "#environment.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "#    'pip==20.2.4'],\n",
        "#    pip_packages=[\n",
        "#    'azureml-defaults',\n",
        "#    'inference-schema[numpy-support]',\n",
        "#    'joblib',\n",
        "#    'numpy',\n",
        "#    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "#])\n",
        "\n",
        "\n",
        "print(\"Env is get ready\")\n",
        "\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=score_file, environment = environment)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "print(\"start deployment\" + model_deployed.name)\n",
        "service = Model.deploy(workspace=run.experiment.workspace,\n",
        "                       name=service_name,\n",
        "                       models=[model_deployed],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "\n",
        "#print(service.get_logs())\n",
        "\n",
        "print(service.scoring_uri)\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model/register_deploy.py\n"
        }
      ],
      "execution_count": 101,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup computer resource for running Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"amlcluster\"\n",
        "\n",
        "# Verify that cluster exists\n",
        "try:\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If not, create it\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4,\n",
        "                                                           idle_seconds_before_scaledown=5400)\n",
        "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    pipeline_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 94,
      "metadata": {
        "gather": {
          "logged": 1669910982214
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set build pipeline and pipeline running environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a RunConfiguration to specify some additional requirements for this step.\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.runconfig import DockerConfiguration \r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# create a new runconfig object\r\n",
        "run_config = RunConfiguration()\r\n",
        "\r\n",
        "# enable Docker \r\n",
        "#run_config.environment.docker.enabled = True\r\n",
        "run_config.docker = DockerConfiguration(use_docker = True)\r\n",
        "\r\n",
        "# set Docker base image to the default CPU-based image\r\n",
        "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\r\n",
        "run_config.environment.python.user_managed_dependencies = False\r\n",
        "\r\n",
        "# specify CondaDependencies obj\r\n",
        "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn','pandas'],\r\n",
        "                                                                            pip_packages=['azureml-sdk'], python_version='3.8.13')"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669883337696
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to be removed\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.runconfig import DockerConfiguration\r\n",
        "\r\n",
        "# Create a Python environment for the experiment\r\n",
        "diabetes_env = Environment(\"diabetes-pipeline-env\")\r\n",
        "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\r\n",
        "diabetes_env.docker.enabled = True # Use a docker container\r\n",
        "\r\n",
        "# Create a set of package dependencies\r\n",
        "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas'],\r\n",
        "                                             pip_packages=['azureml-sdk'])\r\n",
        "\r\n",
        "# Add the dependencies to the environment\r\n",
        "diabetes_env.python.conda_dependencies = diabetes_packages\r\n",
        "\r\n",
        "# Register the environment (just in case you want to use it again)\r\n",
        "diabetes_env.register(workspace=ws)\r\n",
        "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\r\n",
        "\r\n",
        "# Create a new runconfig object for the pipeline\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above. \r\n",
        "pipeline_run_config.target = pipeline_cluster\r\n",
        "\r\n",
        "# enable Docker \r\n",
        "#run_config.environment.docker.enabled = True\r\n",
        "pipeline_run_config.docker = DockerConfiguration(use_docker = True)\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669880151768
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct Pipeline input parameter and pipelin steps"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use this later in publishing pipeline\r\n",
        "pipeline_param = PipelineParameter(name=\"config_pipeline_arg\", default_value=\"\")\r\n",
        "print(\"pipeline parameter created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "pipeline parameter created\n"
        }
      ],
      "execution_count": 119,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669951914854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Syntax\r\n",
        "# PythonScriptStep(\r\n",
        "#     script_name, \r\n",
        "#     name=None, \r\n",
        "#     arguments=None, \r\n",
        "#     compute_target=None, \r\n",
        "#     runconfig=None, \r\n",
        "#     inputs=None, \r\n",
        "#     outputs=None, \r\n",
        "#     params=None, \r\n",
        "#     source_directory=None, \r\n",
        "#     allow_reuse=True, \r\n",
        "#     version=None, \r\n",
        "#     hash_paths=None)\r\n",
        "# This returns a Step\r\n",
        "prepare_step = PythonScriptStep(name=\"prepare\",\r\n",
        "                         script_name=\"prepare.py\",\r\n",
        "                         arguments=['--output_folder', model_folder,\"--pipeline_param\", pipeline_param], \r\n",
        "                         compute_target=pipeline_cluster, \r\n",
        "                         source_directory=model_register_folder,\r\n",
        "                         outputs=[model_folder],\r\n",
        "                         runconfig = run_config,\r\n",
        "                         allow_reuse=True)\r\n",
        "print(\"prepare_step created\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "prepare_step created\n"
        }
      ],
      "execution_count": 121,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669951920943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2, run the model registration script\r\n",
        "register_step = PythonScriptStep(name = \"Register Model\",\r\n",
        "                                source_directory = model_register_folder,\r\n",
        "                                script_name = \"register_deploy.py\",\r\n",
        "                                arguments = ['--model_folder', model_folder],\r\n",
        "                                inputs=[model_folder],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "print(\"register_step created\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "register_step created\n"
        }
      ],
      "execution_count": 122,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669951924896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test input parameter for pipeline\r\n",
        "config_file = \"https://raw.githubusercontent.com/leonlj/mlopstmptest/main/parameters.json\""
      ],
      "outputs": [],
      "execution_count": 130,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669964130123
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debug pipeline, run pipeline with experiement"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for temporary pipeline parameter testing\r\n",
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [prepare_step, register_step]\r\n",
        "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace = ws, name = 'testparam-model-release-pipeline')\r\n",
        "pipeline_run_with_param = experiment.submit(pipeline, pipeline_parameters={'config_pipeline_arg': config_file}, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "\r\n",
        "RunDetails(pipeline_run_with_param).show()\r\n",
        "pipeline_run_with_param.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step prepare [3300efcc][158237fd-5552-44b7-87c8-b24516d1b35e], (This step will run and generate new outputs)\nCreated step Register Model [421749f1][2b06def4-13ba-4f42-8341-21b847f34dca], (This step will run and generate new outputs)\nSubmitted PipelineRun e6c20870-5483-49cb-a39b-5601ed72ebd1\nLink to Azure Machine Learning Portal: https://studio.ml.azure.cn/runs/e6c20870-5483-49cb-a39b-5601ed72ebd1?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c551982c9acd4876a76c3fb294154e60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://studio.ml.azure.cn/runs/e6c20870-5483-49cb-a39b-5601ed72ebd1?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\", \"run_id\": \"e6c20870-5483-49cb-a39b-5601ed72ebd1\", \"run_properties\": {\"run_id\": \"e6c20870-5483-49cb-a39b-5601ed72ebd1\", \"created_utc\": \"2022-12-02T03:32:09.96771Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{\\\"config_pipeline_arg\\\":\\\"https://raw.githubusercontent.com/leonlj/mlopstmptest/main/parameters.json\\\"}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\", \"azureml.pipelines.stages\": \"{\\\"Initialization\\\":null,\\\"Execution\\\":{\\\"StartTime\\\":\\\"2022-12-02T03:32:11.2112353+00:00\\\",\\\"EndTime\\\":\\\"2022-12-02T03:33:58.7427087+00:00\\\",\\\"Status\\\":\\\"Finished\\\"}}\"}, \"tags\": {}, \"end_time_utc\": \"2022-12-02T03:33:58.824116Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.e6c20870-5483-49cb-a39b-5601ed72ebd1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=1vnGFHbrOdUfxaCS61dV3U936v24nDNMh8A%2FbNaLf38%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A16%3A23Z&ske=2022-12-03T11%3A26%3A23Z&sks=b&skv=2019-07-07&st=2022-12-02T07%3A06%3A13Z&se=2022-12-02T15%3A16%3A13Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.e6c20870-5483-49cb-a39b-5601ed72ebd1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=sueP1hgx2B3OXIybCCOOMnS0dGXdNAR1IMVZ2X7CzC8%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A16%3A23Z&ske=2022-12-03T11%3A26%3A23Z&sks=b&skv=2019-07-07&st=2022-12-02T07%3A06%3A13Z&se=2022-12-02T15%3A16%3A13Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.e6c20870-5483-49cb-a39b-5601ed72ebd1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=fLFikXqloEZb6lpqKNXKroQfmAYshuFber%2B40esnFk0%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A16%3A23Z&ske=2022-12-03T11%3A26%3A23Z&sks=b&skv=2019-07-07&st=2022-12-02T07%3A06%3A13Z&se=2022-12-02T15%3A16%3A13Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:01:48\", \"run_number\": \"1669951929\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"0a418f9c-9f01-4caf-a82a-d9de4723d533\", \"name\": \"prepare\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T03:32:21.781163Z\", \"created_time\": \"2022-12-02T03:32:11.940176Z\", \"end_time\": \"2022-12-02T03:32:51.789118Z\", \"duration\": \"0:00:39\", \"run_number\": 1669951931, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T03:32:11.940176Z\", \"is_reused\": \"\"}, {\"run_id\": \"edbe55a1-a220-4a37-b06f-4e4604dabd1f\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T03:33:02.33928Z\", \"created_time\": \"2022-12-02T03:32:53.39344Z\", \"end_time\": \"2022-12-02T03:33:57.811548Z\", \"duration\": \"0:01:04\", \"run_number\": 1669951973, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T03:32:53.39344Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-12-02 03:32:11Z] Submitting 1 runs, first five are: 3300efcc:0a418f9c-9f01-4caf-a82a-d9de4723d533\\n[2022-12-02 03:32:52Z] Completing processing run id 0a418f9c-9f01-4caf-a82a-d9de4723d533.\\n[2022-12-02 03:32:52Z] Submitting 1 runs, first five are: 421749f1:edbe55a1-a220-4a37-b06f-4e4604dabd1f\\n[2022-12-02 03:33:58Z] Completing processing run id edbe55a1-a220-4a37-b06f-4e4604dabd1f.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"3300efcc\": {\"node_id\": \"3300efcc\", \"name\": \"prepare\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"0a418f9c-9f01-4caf-a82a-d9de4723d533\"}, \"421749f1\": {\"node_id\": \"421749f1\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"edbe55a1-a220-4a37-b06f-4e4604dabd1f\"}}, \"edges\": [{\"source_node_id\": \"3300efcc\", \"source_node_name\": \"prepare\", \"source_name\": \"model_release_folder\", \"target_name\": \"model_release_folder\", \"dst_node_id\": \"421749f1\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"0a418f9c-9f01-4caf-a82a-d9de4723d533\", \"name\": \"prepare\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T03:32:21.781163Z\", \"created_time\": \"2022-12-02T03:32:11.940176Z\", \"end_time\": \"2022-12-02T03:32:51.789118Z\", \"duration\": \"0:00:39\", \"run_number\": 1669951931, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T03:32:11.940176Z\", \"is_reused\": \"\"}, {\"run_id\": \"edbe55a1-a220-4a37-b06f-4e4604dabd1f\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T03:33:02.33928Z\", \"created_time\": \"2022-12-02T03:32:53.39344Z\", \"end_time\": \"2022-12-02T03:33:57.811548Z\", \"duration\": \"0:01:04\", \"run_number\": 1669951973, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T03:32:53.39344Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: e6c20870-5483-49cb-a39b-5601ed72ebd1\nLink to Azure Machine Learning Portal: https://studio.ml.azure.cn/runs/e6c20870-5483-49cb-a39b-5601ed72ebd1?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 0a418f9c-9f01-4caf-a82a-d9de4723d533\nLink to Azure Machine Learning Portal: https://studio.ml.azure.cn/runs/0a418f9c-9f01-4caf-a82a-d9de4723d533?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\nStepRun( prepare ) Status: Queued\n\nStreaming azureml-logs/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n========================================================================================================================\n2022-12-02T03:32:23Z Executing 'Copy ACR Details file' on 10.0.0.4\n2022-12-02T03:32:23Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_0c7394fe55586ee356098eaded0937ad\nDigest: sha256:d5a66549ecb608de82a5d6f639f8977e0019a4041573e4809805f60f8de424d0\nStatus: Image is up to date for leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad:latest\nleonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad:latest\n2022-12-02T03:32:23Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=85488 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-12-02T03:32:23Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore -- stdout/stderr: \n2022-12-02T03:32:24Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:32:24Z Starting output-watcher...\n2022-12-02T03:32:24Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2022-12-02T03:32:24Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:32:24Z Check if container 0a418f9c-9f01-4caf-a82a-d9de4723d533 already exist exited with 0, \n\n2606636730af58289a1de9dfa247366f9f99cb7401ef14ee9a94da0ff24ccac6\n2022-12-02T03:32:24Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-12-02T03:32:24Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-af4b5419a6b0e1ae7b9d567d50ff8120-06dc6be128c23199-01 -sshRequired=false] \n2022/12/02 03:32:24 Got JobInfoJson from env\n2022/12/02 03:32:24 Starting App Insight Logger for task:  containerSetup\n2022/12/02 03:32:24 Version: 3.0.02140.0005 Branch: .SourceBranch Commit: d67fb6d\n2022/12/02 03:32:24 Entered ContainerSetupTask - Preparing infiniband\n2022/12/02 03:32:24 Starting infiniband setup\n2022/12/02 03:32:24 Python Version found is Python 3.8.13\n\n2022/12/02 03:32:24 Returning Python Version as 3.8\n2022-12-02T03:32:24Z VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2022-12-02T03:32:24Z Not setting up Infiniband in Container\n2022/12/02 03:32:24 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2022/12/02 03:32:24 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2022/12/02 03:32:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022/12/02 03:32:24 Not setting up Infiniband in Container\n2022/12/02 03:32:24 Not setting up Infiniband in Container\n2022/12/02 03:32:24 Python Version found is Python 3.8.13\n\n2022/12/02 03:32:24 Returning Python Version as 3.8\n2022/12/02 03:32:24 sshd inside container not required for job, skipping setup.\n2022/12/02 03:32:25 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/12/02 03:32:25 App Insight Client has already been closed\n2022/12/02 03:32:25 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-12-02T03:32:25Z Starting docker container succeeded.\n2022-12-02T03:32:28Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:32:28Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:32:28Z Job environment preparation succeeded on 10.0.0.4. Output: \n>>>   2022/12/02 03:32:23 Got JobInfoJson from env\n>>>   2022/12/02 03:32:23 Starting App Insight Logger for task:  prepareJobEnvironment\n>>>   2022/12/02 03:32:23 Version: 3.0.02140.0005 Branch: .SourceBranch Commit: d67fb6d\n>>>   2022/12/02 03:32:23 Got JobInfoJson from env\n>>>   2022/12/02 03:32:23 runtime.GOOS linux\n>>>   2022/12/02 03:32:23 Checking if '/tmp' exists\n>>>   2022/12/02 03:32:23 Reading dyanamic configs\n>>>   2022/12/02 03:32:23 Starting Azsecpack installation on machine: 557066be728f4ade9a6261b30fffba08000000#fb79b746-da69-43ae-8666-e506470b969c#f7ccde76-13d3-4104-a67c-a396e59e872b#leonamljci#leonamltestcn#amlcluster#tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d\n>>>   2022/12/02 03:32:23 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n>>>   2022/12/02 03:32:23 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n>>>   2022/12/02 03:32:23 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n>>>   2022/12/02 03:32:23 Turning off azsecpack, if it is already running\n>>>   2022/12/02 03:32:23 Start deleting Azsecpack installation cronjob...\n>>>   2022/12/02 03:32:23 Start checking if Azsecpack is running...\n>>>   2022/12/02 03:32:23 Azsecpack is not running. No need to stop Azsecpack processes.\n>>>   2022/12/02 03:32:23 bypass systemd resolved\n>>>   2022/12/02 03:32:23 Cluster Subscription Id: f7ccde76-13d3-4104-a67c-a396e59e872b\n>>>   2022/12/02 03:32:23 Cluster Workspace Name: leonamltestcn\n>>>   2022/12/02 03:32:23 Cluster Name: amlcluster\n>>>   2022/12/02 03:32:23 VMsize: standard_d2_v2\n>>>   2022/12/02 03:32:23 GPU Count: 0\n>>>   2022/12/02 03:32:23 XdsEndpoint:: XDS endpoint not recognized as old endpoint: https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai\n>>>   2022/12/02 03:32:23 XdsEndpoint:: Overwrite xds endpoint for AmlCompute to: https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai\n>>>   2022/12/02 03:32:23 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n>>>   2022/12/02 03:32:23 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:23 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:23 Get GPU count failed with err: The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n>>>   2022/12/02 03:32:23 AMLComputeXDSEndpoint:  https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai\n>>>   2022/12/02 03:32:23 AMLComputeXDSApiVersion:  2018-02-01\n>>>   2022/12/02 03:32:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/config\n>>>   2022/12/02 03:32:23 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n>>>   2022/12/02 03:32:23 Starting identity responder.\n>>>   2022/12/02 03:32:23 Starting identity responder.\n>>>   2022/12/02 03:32:23 Logfile used for identity responder: /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/IdentityResponderLog-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:32:23 Logfile used for identity responder: /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/IdentityResponderLog-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:32:23 Started Identity Responder for job.\n>>>   2022/12/02 03:32:23 Started Identity Responder for job.\n>>>   2022/12/02 03:32:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd\n>>>   2022/12/02 03:32:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/shared\n>>>   2022/12/02 03:32:23 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:23 From the policy service, the filtering patterns is: , data store is \n>>>   2022/12/02 03:32:23 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2022/12/02 03:32:23 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2022/12/02 03:32:23 SidecarEnabled:: sidecar not enabled\n>>>   2022/12/02 03:32:23 Start to pulling docker image: leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad\n>>>   2022/12/02 03:32:23 Start pull docker image: leonamltestc6b7a4af2.azurecr.cn\n>>>   2022/12/02 03:32:23 Getting credentials for image leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad with url leonamltestc6b7a4af2.azurecr.cn\n>>>   2022/12/02 03:32:23 Container registry is ACR.\n>>>   2022/12/02 03:32:23 Skip getting ACR Credentials from Identity and will be getting it from EMS\n>>>   2022/12/02 03:32:23 Getting ACR Credentials from EMS for environment Experiment testparam-model-release-pipeline Environment:Autosave_2022-12-02T03:04:13Z_0aaeb215\n>>>   2022/12/02 03:32:23 Requesting XDS for registry details.\n>>>   2022/12/02 03:32:23 Attempt 1 of http call to https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai/hosttoolapi/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/workspaces/leonamltestcn/clusters/amlcluster/nodes/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d?api-version=2018-02-01\n>>>   2022/12/02 03:32:23 Got container registry details from credentials service for registry address: leonamltestc6b7a4af2.azurecr.cn.\n>>>   2022/12/02 03:32:23 Writing ACR Details to file...\n>>>   2022/12/02 03:32:23 Copying ACR Details file to worker nodes...\n>>>   2022/12/02 03:32:23 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2022/12/02 03:32:23 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2022/12/02 03:32:23 Begin executing 'Copy ACR Details file' task on Node\n>>>   2022/12/02 03:32:23 'Copy ACR Details file' task Node result: succeeded\n>>>   2022/12/02 03:32:23 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2022/12/02 03:32:23 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2022/12/02 03:32:23 Successfully retrieved ACR Credentials from EMS.\n>>>   2022/12/02 03:32:23 EMS returned leonamltestc6b7a4af2.azurecr.cn for environment Experiment testparam-model-release-pipeline Environment\n>>>   2022/12/02 03:32:23 Save docker credentials for image leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad in /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/docker_login_0F9F2FF7FD7F3FF4\n>>>   2022/12/02 03:32:23 Start login to the docker registry\n>>>   2022/12/02 03:32:23 Successfully logged into the docker registry.\n>>>   2022/12/02 03:32:23 Start run pull docker image command\n>>>   2022/12/02 03:32:23 Pull docker image succeeded.\n>>>   2022/12/02 03:32:23 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/docker_login_0F9F2FF7FD7F3FF4\n>>>   2022/12/02 03:32:23 Pull docker image time: 324.036206ms\n>>>   \n>>>   2022/12/02 03:32:23 Mounting job level file systems\n>>>   2022/12/02 03:32:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts\n>>>   2022/12/02 03:32:23 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/config/.amlcompute.datastorecredentials\n>>>   2022/12/02 03:32:23 Datastore credentials file not found, skipping.\n>>>   2022/12/02 03:32:23 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/config/.master.runtimesastokens\n>>>   2022/12/02 03:32:23 Runtime sas tokens file not found, skipping.\n>>>   2022/12/02 03:32:23 NFS mount is not enabled\n>>>   2022/12/02 03:32:23 No Azure File Shares configured\n>>>   2022/12/02 03:32:23 Mounting blob file systems\n>>>   2022/12/02 03:32:23 Blobfuse runtime version 1.3.7\n>>>   2022/12/02 03:32:23 Mounting azureml-blobstore-68554b4b-1bce-4ce3-85ea-55afaf22fe5f container from leonamltestcn4641503574 account at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore\n>>>   2022/12/02 03:32:23 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2022/12/02 03:32:23 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2022/12/02 03:32:23 Blobfuse cache size set to 85488 MB.\n>>>   2022/12/02 03:32:23 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=85488 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n>>>   2022/12/02 03:32:23 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=85488 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n>>>   2022/12/02 03:32:23 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore -- stdout/stderr: \n>>>   2022/12/02 03:32:23 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore -- stdout/stderr: \n>>>   2022/12/02 03:32:23 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore\n>>>   2022/12/02 03:32:23 Successfully mounted azureml-blobstore-68554b4b-1bce-4ce3-85ea-55afaf22fe5f container from leonamltestcn4641503574 account at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore\n>>>   2022/12/02 03:32:24 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 No unmanaged file systems configured\n>>>   2022/12/02 03:32:24 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:24 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:24 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 From the policy service, the filtering patterns is: , data store is \n>>>   2022/12/02 03:32:24 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs\n>>>   2022/12/02 03:32:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d\n>>>   2022/12/02 03:32:24 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:32:24 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs\n>>>   2022/12/02 03:32:24 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs\n>>>   2022/12/02 03:32:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs\n>>>   2022/12/02 03:32:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d\n>>>   2022/12/02 03:32:24 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:32:24 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs\n>>>   2022/12/02 03:32:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/logs\n>>>   2022/12/02 03:32:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/outputs\n>>>   2022/12/02 03:32:24 Starting output-watcher...\n>>>   2022/12/02 03:32:24 Single file input dataset is enabled.\n>>>   2022/12/02 03:32:24 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2022/12/02 03:32:24 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2022/12/02 03:32:24 SidecarEnabled:: sidecar not enabled\n>>>   2022/12/02 03:32:24 Docker Version that this nodes use are: 20.10.17+azure-1\n>>>   \n>>>   2022/12/02 03:32:24 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:24 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:24 Setting the memory limit for docker container to be 6618 MB\n>>>   2022/12/02 03:32:24 The env variable file size is 38030 bytes\n>>>   2022/12/02 03:32:24 Creating parent cgroup '0a418f9c-9f01-4caf-a82a-d9de4723d533' for Containers used in Job\n>>>   2022/12/02 03:32:24 Add parent cgroup '0a418f9c-9f01-4caf-a82a-d9de4723d533' to container '0a418f9c-9f01-4caf-a82a-d9de4723d533'\n>>>   2022/12/02 03:32:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n>>>   2022/12/02 03:32:24 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,0a418f9c-9f01-4caf-a82a-d9de4723d533,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/certs:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,6618m,-v,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/config/.batchai.envlist,--cgroup-parent=/0a418f9c-9f01-4caf-a82a-d9de4723d533/,--shm-size,2g\n>>>   2022/12/02 03:32:24 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n>>>   2022/12/02 03:32:24 the binding /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533 \n>>>   2022/12/02 03:32:24 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,0a418f9c-9f01-4caf-a82a-d9de4723d533,-m,6618m,-w,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/config/.batchai.envlist,--cgroup-parent=/0a418f9c-9f01-4caf-a82a-d9de4723d533/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/certs:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/certs\n>>>   2022/12/02 03:32:24 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 0a418f9c-9f01-4caf-a82a-d9de4723d533 -m 6618m -w /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/config/.batchai.envlist --cgroup-parent=/0a418f9c-9f01-4caf-a82a-d9de4723d533/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533 -v /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd -v /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/certs:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/certs -d -it --privileged --net=host leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad\n>>>   2022/12/02 03:32:24 Check if container 0a418f9c-9f01-4caf-a82a-d9de4723d533 already exist exited with 0, \n>>>   \n>>>   2022/12/02 03:32:24 Check if container 0a418f9c-9f01-4caf-a82a-d9de4723d533 already exist exited with 0, \n>>>   \n>>>   2022/12/02 03:32:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2022/12/02 03:32:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2022/12/02 03:32:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-af4b5419a6b0e1ae7b9d567d50ff8120-06dc6be128c23199-01 -sshRequired=false] \n>>>   2022/12/02 03:32:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-af4b5419a6b0e1ae7b9d567d50ff8120-06dc6be128c23199-01 -sshRequired=false] \n>>>   2022/12/02 03:32:25 Container ssh is not required for job type.\n>>>   2022/12/02 03:32:25 Starting docker container succeeded.\n>>>   2022/12/02 03:32:25 Starting docker container succeeded.\n>>>   2022/12/02 03:32:25 Disk space after starting docker container: 87994MB\n>>>   2022/12/02 03:32:25 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2022/12/02 03:32:25 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2022/12/02 03:32:25 SidecarEnabled:: sidecar not enabled\n>>>   2022/12/02 03:32:25 Begin execution of runSpecialJobTask\n>>>   2022/12/02 03:32:25 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n>>>   2022/12/02 03:32:25 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs\n>>>   2022/12/02 03:32:25 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs\n>>>   2022/12/02 03:32:25 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/bin/python /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"67990d0e-6989-4285-b64c-24739537aaea\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null,\"SnapshotAssetId\":null}]'\n>>>   2022/12/02 03:32:25 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:32:25 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml_compute_logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:32:25 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533;/azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/bin/python /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"67990d0e-6989-4285-b64c-24739537aaea\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null,\"SnapshotAssetId\":null}]'\n>>>   2022/12/02 03:32:25 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n>>>   2022/12/02 03:32:25 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-af4b5419a6b0e1ae7b9d567d50ff8120-c83ba90d10ff335d-01 -t 0a418f9c-9f01-4caf-a82a-d9de4723d533 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/0a418f9c-9f01-4caf-a_728ffc8b-48c2-4dc7-8c63-e6678dc8ea4a/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/wd/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533;/azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/bin/python /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"67990d0e-6989-4285-b64c-24739537aaea\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null,\"SnapshotAssetId\":null}]'\n>>>   2022/12/02 03:32:28 containerName:0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:28 sidecar containerName:0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   2022/12/02 03:32:28 Docker Version that this nodes use are: 20.10.17+azure-1\n>>>   \n>>>   2022/12/02 03:32:28 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:28 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:28 sidecar dockerLauncher:docker\n>>>   2022/12/02 03:32:28 Attempt 1 of http call to https://chinaeast2.api.ml.azure.cn/history/v1.0/private/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/runs/0a418f9c-9f01-4caf-a82a-d9de4723d533/spans\n>>>   2022/12/02 03:32:28 sidecarContainerId:2606636730af58289a1de9dfa247366f9f99cb7401ef14ee9a94da0ff24ccac6\n>>>   2022/12/02 03:32:28 Docker Version that this nodes use are: 20.10.17+azure-1\n>>>   \n>>>   2022/12/02 03:32:28 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:28 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:32:28 Docker logs for 0a418f9c-9f01-4caf-a82a-d9de4723d533\n>>>   \n>>>   2022/12/02 03:32:28 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n>>>   \n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:25.572135] Entering job preparation.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.727627] Starting job preparation.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.727662] Extracting the control code.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.727978] Starting extract_project.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.728018] Starting to extract zip file.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.743809] Finished extracting zip file.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.747170] Using urllib.request Python 3.0 or later\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.747209] Start fetching snapshots.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:26.747280] Start fetching snapshot.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 46\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.271851] Finished fetching snapshot.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.271893] Finished fetching snapshots.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.271914] Finished extract_project.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.272046] Finished fetching and extracting the control code.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.276359] downloadDataStore - Download from datastores if requested.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.277621] Start run_history_prep.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.282172] Entering context manager injector.\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: Acquired lockfile /tmp/0a418f9c-9f01-4caf-a82a-d9de4723d533-datastore.lock to downloading input data references\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.966474] downloadDataStore completed\n>>>   2022/12/02 03:32:28 runSpecialJobTask: preparation: [2022-12-02T03:32:27.969938] Job preparation is complete.\n>>>   2022/12/02 03:32:28 DockerSideCarContainerLogs:\n>>>   \n>>>   2022/12/02 03:32:28 DockerSideCarContainerLogs End\n>>>   2022/12/02 03:32:28 Execution of runSpecialJobTask completed\n>>>   2022/12/02 03:32:28 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n>>>   Stopped: false\n>>>   OriginalData: 2\n>>>   FilteredData: 0.\n>>>   2022/12/02 03:32:28 Process Exiting with Code:  0\n>>>   2022/12/02 03:32:28 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n>>>   \n2022-12-02T03:32:28Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:32:28Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:32:28Z 127.0.0.1 slots=2 max-slots=2\n2022-12-02T03:32:29Z launching Custom job\n2022-12-02T03:32:37Z job exited with code 0\n2022-12-02T03:32:37Z Executing 'JobRelease task' on 10.0.0.4\nStepRun( prepare ) Status: Running\n\nStreaming azureml-logs/75_job_post-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n===============================================================================================================\n[2022-12-02T03:32:38.141291] Entering job release\n[2022-12-02T03:32:39.096891] Starting job release\n[2022-12-02T03:32:39.110502] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 162\n[2022-12-02T03:32:39.115160] job release stage : upload_datastore starting...\n[2022-12-02T03:32:39.123401] job release stage : start importing azureml.history._tracking in run_history_release.\n[2022-12-02T03:32:39.133906] job release stage : copy_batchai_cached_logs starting...\n[2022-12-02T03:32:39.135592] Entering context manager injector.[2022-12-02T03:32:39.136080] job release stage : copy_batchai_cached_logs completed...\n\n[2022-12-02T03:32:39.136518] job release stage : execute_job_release starting...\n[2022-12-02T03:32:39.235845] job release stage : upload_datastore completed...\n[2022-12-02T03:32:39.237282] job release stage : send_run_telemetry starting...\n[2022-12-02T03:32:39.258280] get vm size and vm region successfully.\n[2022-12-02T03:32:39.272506] get compute meta data successfully.\n[2022-12-02T03:32:39.439754] post artifact meta request successfully.\n[2022-12-02T03:32:39.462285] job release stage : execute_job_release completed...\n[2022-12-02T03:32:39.489101] upload compute record artifact successfully.\n[2022-12-02T03:32:39.489244] job release stage : send_run_telemetry completed...\n[2022-12-02T03:32:39.489571] Job release is complete\n\nStepRun(prepare) Execution Summary\n===================================\nStepRun( prepare ) Status: Finished\n{'runId': '0a418f9c-9f01-4caf-a82a-d9de4723d533', 'target': 'amlcluster', 'status': 'Completed', 'startTimeUtc': '2022-12-02T03:32:21.781163Z', 'endTimeUtc': '2022-12-02T03:32:51.789118Z', 'services': {}, 'properties': {'ContentSnapshotId': '67990d0e-6989-4285-b64c-24739537aaea', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '158237fd-5552-44b7-87c8-b24516d1b35e', 'azureml.moduleName': 'prepare', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '3300efcc', 'azureml.pipelinerunid': 'e6c20870-5483-49cb-a39b-5601ed72ebd1', 'azureml.pipeline': 'e6c20870-5483-49cb-a39b-5601ed72ebd1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'prepare.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_release_folder', '--pipeline_param', '$AML_PARAMETER_config_pipeline_arg'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'amlcluster', 'dataReferences': {'model_release_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment testparam-model-release-pipeline Environment', 'version': 'Autosave_2022-12-02T03:04:13Z_0aaeb215', 'assetId': 'azureml://locations/chinaeast2/workspaces/68554b4b-1bce-4ce3-85ea-55afaf22fe5f/environments/Experiment testparam-model-release-pipeline Environment/versions/Autosave_2022-12-02T03:04:13Z_0aaeb215', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.8.13', {'pip': ['azureml-sdk~=1.34.0']}, 'scikit-learn', 'pandas'], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_config_pipeline_arg': 'https://raw.githubusercontent.com/leonlj/mlopstmptest/main/parameters.json'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt?sv=2019-07-07&sr=b&sig=s%2BdQAXx4TkTsSQGhFUoXf29grKhcM3d0DA1trxmq2hc%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'azureml-logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt?sv=2019-07-07&sr=b&sig=AoyoqlVv%2FrMB9IHUMly6HpYM9a5%2F4jdVj8zOUaZNMQA%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=8Sp6tIUXY189meLtjAsQaXfrkKcqxKohdfjxXVav7Gc%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'azureml-logs/75_job_post-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs/75_job_post-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt?sv=2019-07-07&sr=b&sig=KWQacYQFrOeHp1ggXEfHaoiMIhnv8rffOedBlH7s3S0%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'azureml-logs/process_info.json': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=XWoe6pSa4vFhaFSWpfXStMJaGHP45uRM%2Bs1ctFZcXlo%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'azureml-logs/process_status.json': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=LPKIeseC5T5OMcIPaj90r4Hx1CKBWUKd1Z6yJwMS0hs%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'logs/azureml/106_azureml.log': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/106_azureml.log?sv=2019-07-07&sr=b&sig=h%2BuRMzyLWVwHPceg0%2BlmS2cp6JzQURskTxI3ZbftDbI%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A11Z&ske=2022-12-03T11%3A04%3A11Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=QRo65R0RVEuSdiKs9ebwBiuswuUKRs5teBrQBhrQFH8%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A11Z&ske=2022-12-03T11%3A04%3A11Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=%2B7L7OGl09ezUSau17JeYqw7TBx%2FygiiTGOsLdWUIXiw%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A11Z&ske=2022-12-03T11%3A04%3A11Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=suP%2Be%2FpNa1PRbMslOPxmpaMkvb1rC7HQFAZSTzG1ddo%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A11Z&ske=2022-12-03T11%3A04%3A11Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=9u7SEB9xYqcoxbSxUrw0ycC5A0Qnsth1XmS1c2RbMe8%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A11Z&ske=2022-12-03T11%3A04%3A11Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.0a418f9c-9f01-4caf-a82a-d9de4723d533/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=XzKR1tbyRVT1hJbsJbu23gdoAKcGT09HkITlmPJZU3Y%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A11Z&ske=2022-12-03T11%3A04%3A11Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A43Z&se=2022-12-02T11%3A32%3A43Z&sp=r'}, 'submittedBy': 'leliang'}\n\n\n\n\nStepRunId: edbe55a1-a220-4a37-b06f-4e4604dabd1f\nLink to Azure Machine Learning Portal: https://studio.ml.azure.cn/runs/edbe55a1-a220-4a37-b06f-4e4604dabd1f?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\nStepRun( Register Model ) Status: NotStarted\n\nStreaming azureml-logs/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n========================================================================================================================\n2022-12-02T03:33:03Z Executing 'Copy ACR Details file' on 10.0.0.4\n2022-12-02T03:33:03Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_0c7394fe55586ee356098eaded0937ad\nDigest: sha256:d5a66549ecb608de82a5d6f639f8977e0019a4041573e4809805f60f8de424d0\nStatus: Image is up to date for leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad:latest\nleonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad:latest\n2022-12-02T03:33:04Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=85488 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-12-02T03:33:04Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore -- stdout/stderr: \n2022-12-02T03:33:04Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:33:04Z Starting output-watcher...\n2022-12-02T03:33:04Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2022-12-02T03:33:04Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:33:04Z Check if container edbe55a1-a220-4a37-b06f-4e4604dabd1f already exist exited with 0, \n\n0217863a73579bbf3a96dc7ad4e0b91e8407f98c014468f4eccaf946e16b6d8e\nStepRun( Register Model ) Status: Running\n2022-12-02T03:33:04Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-12-02T03:33:04Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-122defeb0379cb60e175edfd018a72c3-4aa69c57ab758d74-01 -sshRequired=false] \n2022/12/02 03:33:04 Got JobInfoJson from env\n2022/12/02 03:33:04 Starting App Insight Logger for task:  containerSetup\n2022/12/02 03:33:04 Version: 3.0.02140.0005 Branch: .SourceBranch Commit: d67fb6d\n2022/12/02 03:33:04 Entered ContainerSetupTask - Preparing infiniband\n2022/12/02 03:33:04 Starting infiniband setup\n2022/12/02 03:33:04 Python Version found is Python 3.8.13\n\n2022/12/02 03:33:04 Returning Python Version as 3.8\n2022/12/02 03:33:04 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2022-12-02T03:33:04Z VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2022/12/02 03:33:04 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2022/12/02 03:33:04 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022-12-02T03:33:04Z Not setting up Infiniband in Container\n2022/12/02 03:33:04 Not setting up Infiniband in Container\n2022/12/02 03:33:04 Not setting up Infiniband in Container\n2022/12/02 03:33:04 Python Version found is Python 3.8.13\n\n2022/12/02 03:33:04 Returning Python Version as 3.8\n2022/12/02 03:33:04 sshd inside container not required for job, skipping setup.\n2022/12/02 03:33:05 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/12/02 03:33:05 App Insight Client has already been closed\n2022/12/02 03:33:05 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-12-02T03:33:05Z Starting docker container succeeded.\n2022-12-02T03:33:08Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:33:08Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:33:09Z Job environment preparation succeeded on 10.0.0.4. Output: \n>>>   2022/12/02 03:33:03 Got JobInfoJson from env\n>>>   2022/12/02 03:33:03 Starting App Insight Logger for task:  prepareJobEnvironment\n>>>   2022/12/02 03:33:03 Version: 3.0.02140.0005 Branch: .SourceBranch Commit: d67fb6d\n>>>   2022/12/02 03:33:03 Got JobInfoJson from env\n>>>   2022/12/02 03:33:03 runtime.GOOS linux\n>>>   2022/12/02 03:33:03 Checking if '/tmp' exists\n>>>   2022/12/02 03:33:03 Reading dyanamic configs\n>>>   2022/12/02 03:33:03 Starting Azsecpack installation on machine: 557066be728f4ade9a6261b30fffba08000000#fb79b746-da69-43ae-8666-e506470b969c#f7ccde76-13d3-4104-a67c-a396e59e872b#leonamljci#leonamltestcn#amlcluster#tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d\n>>>   2022/12/02 03:33:03 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n>>>   2022/12/02 03:33:03 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n>>>   2022/12/02 03:33:03 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n>>>   2022/12/02 03:33:03 Turning off azsecpack, if it is already running\n>>>   2022/12/02 03:33:03 Start deleting Azsecpack installation cronjob...\n>>>   2022/12/02 03:33:03 Start checking if Azsecpack is running...\n>>>   2022/12/02 03:33:03 Azsecpack is not running. No need to stop Azsecpack processes.\n>>>   2022/12/02 03:33:03 bypass systemd resolved\n>>>   2022/12/02 03:33:03 Cluster Subscription Id: f7ccde76-13d3-4104-a67c-a396e59e872b\n>>>   2022/12/02 03:33:03 Cluster Workspace Name: leonamltestcn\n>>>   2022/12/02 03:33:03 Cluster Name: amlcluster\n>>>   2022/12/02 03:33:03 VMsize: standard_d2_v2\n>>>   2022/12/02 03:33:03 GPU Count: 0\n>>>   2022/12/02 03:33:03 XdsEndpoint:: XDS endpoint not recognized as old endpoint: https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai\n>>>   2022/12/02 03:33:03 XdsEndpoint:: Overwrite xds endpoint for AmlCompute to: https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai\n>>>   2022/12/02 03:33:03 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n>>>   2022/12/02 03:33:03 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:03 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:03 Get GPU count failed with err: The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n>>>   2022/12/02 03:33:03 AMLComputeXDSEndpoint:  https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai\n>>>   2022/12/02 03:33:03 AMLComputeXDSApiVersion:  2018-02-01\n>>>   2022/12/02 03:33:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/config\n>>>   2022/12/02 03:33:03 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n>>>   2022/12/02 03:33:03 Starting identity responder.\n>>>   2022/12/02 03:33:03 Starting identity responder.\n>>>   2022/12/02 03:33:03 Logfile used for identity responder: /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/IdentityResponderLog-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:33:03 Logfile used for identity responder: /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/IdentityResponderLog-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:33:03 Started Identity Responder for job.\n>>>   2022/12/02 03:33:03 Started Identity Responder for job.\n>>>   2022/12/02 03:33:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd\n>>>   2022/12/02 03:33:03 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/shared\n>>>   2022/12/02 03:33:03 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:03 From the policy service, the filtering patterns is: , data store is \n>>>   2022/12/02 03:33:03 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2022/12/02 03:33:03 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2022/12/02 03:33:03 SidecarEnabled:: sidecar not enabled\n>>>   2022/12/02 03:33:03 Start to pulling docker image: leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad\n>>>   2022/12/02 03:33:03 Start pull docker image: leonamltestc6b7a4af2.azurecr.cn\n>>>   2022/12/02 03:33:03 Getting credentials for image leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad with url leonamltestc6b7a4af2.azurecr.cn\n>>>   2022/12/02 03:33:03 Container registry is ACR.\n>>>   2022/12/02 03:33:03 Skip getting ACR Credentials from Identity and will be getting it from EMS\n>>>   2022/12/02 03:33:03 Getting ACR Credentials from EMS for environment Experiment testparam-model-release-pipeline Environment:Autosave_2022-12-02T03:04:13Z_0aaeb215\n>>>   2022/12/02 03:33:03 Requesting XDS for registry details.\n>>>   2022/12/02 03:33:03 Attempt 1 of http call to https://chinaeast2.cert.api.ml.azure.cn/xdsbatchai/hosttoolapi/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/workspaces/leonamltestcn/clusters/amlcluster/nodes/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d?api-version=2018-02-01\n>>>   2022/12/02 03:33:03 Got container registry details from credentials service for registry address: leonamltestc6b7a4af2.azurecr.cn.\n>>>   2022/12/02 03:33:03 Writing ACR Details to file...\n>>>   2022/12/02 03:33:03 Copying ACR Details file to worker nodes...\n>>>   2022/12/02 03:33:03 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2022/12/02 03:33:03 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2022/12/02 03:33:03 Begin executing 'Copy ACR Details file' task on Node\n>>>   2022/12/02 03:33:03 'Copy ACR Details file' task Node result: succeeded\n>>>   2022/12/02 03:33:03 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2022/12/02 03:33:03 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2022/12/02 03:33:03 Successfully retrieved ACR Credentials from EMS.\n>>>   2022/12/02 03:33:03 EMS returned leonamltestc6b7a4af2.azurecr.cn for environment Experiment testparam-model-release-pipeline Environment\n>>>   2022/12/02 03:33:03 Save docker credentials for image leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad in /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/docker_login_62C0423470A475B4\n>>>   2022/12/02 03:33:03 Start login to the docker registry\n>>>   2022/12/02 03:33:03 Successfully logged into the docker registry.\n>>>   2022/12/02 03:33:03 Start run pull docker image command\n>>>   2022/12/02 03:33:04 Pull docker image succeeded.\n>>>   2022/12/02 03:33:04 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/docker_login_62C0423470A475B4\n>>>   2022/12/02 03:33:04 Pull docker image time: 263.531297ms\n>>>   \n>>>   2022/12/02 03:33:04 Mounting job level file systems\n>>>   2022/12/02 03:33:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts\n>>>   2022/12/02 03:33:04 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/config/.amlcompute.datastorecredentials\n>>>   2022/12/02 03:33:04 Datastore credentials file not found, skipping.\n>>>   2022/12/02 03:33:04 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/config/.master.runtimesastokens\n>>>   2022/12/02 03:33:04 Runtime sas tokens file not found, skipping.\n>>>   2022/12/02 03:33:04 NFS mount is not enabled\n>>>   2022/12/02 03:33:04 No Azure File Shares configured\n>>>   2022/12/02 03:33:04 Mounting blob file systems\n>>>   2022/12/02 03:33:04 Blobfuse runtime version 1.3.7\n>>>   2022/12/02 03:33:04 Mounting azureml-blobstore-68554b4b-1bce-4ce3-85ea-55afaf22fe5f container from leonamltestcn4641503574 account at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore\n>>>   2022/12/02 03:33:04 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2022/12/02 03:33:04 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2022/12/02 03:33:04 Blobfuse cache size set to 85488 MB.\n>>>   2022/12/02 03:33:04 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=85488 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n>>>   2022/12/02 03:33:04 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=85488 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n>>>   2022/12/02 03:33:04 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore -- stdout/stderr: \n>>>   2022/12/02 03:33:04 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore -- stdout/stderr: \n>>>   2022/12/02 03:33:04 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore\n>>>   2022/12/02 03:33:04 Successfully mounted azureml-blobstore-68554b4b-1bce-4ce3-85ea-55afaf22fe5f container from leonamltestcn4641503574 account at /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore\n>>>   2022/12/02 03:33:04 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 No unmanaged file systems configured\n>>>   2022/12/02 03:33:04 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:04 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:04 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 From the policy service, the filtering patterns is: , data store is \n>>>   2022/12/02 03:33:04 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs\n>>>   2022/12/02 03:33:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d\n>>>   2022/12/02 03:33:04 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:33:04 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs\n>>>   2022/12/02 03:33:04 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs\n>>>   2022/12/02 03:33:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs\n>>>   2022/12/02 03:33:04 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d\n>>>   2022/12/02 03:33:04 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs/tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:33:04 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs\n>>>   2022/12/02 03:33:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs\n>>>   2022/12/02 03:33:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/outputs\n>>>   2022/12/02 03:33:04 Starting output-watcher...\n>>>   2022/12/02 03:33:04 Single file input dataset is enabled.\n>>>   2022/12/02 03:33:04 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2022/12/02 03:33:04 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2022/12/02 03:33:04 SidecarEnabled:: sidecar not enabled\n>>>   2022/12/02 03:33:04 Docker Version that this nodes use are: 20.10.17+azure-1\n>>>   \n>>>   2022/12/02 03:33:04 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:04 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:04 Setting the memory limit for docker container to be 6618 MB\n>>>   2022/12/02 03:33:04 The env variable file size is 37665 bytes\n>>>   2022/12/02 03:33:04 Creating parent cgroup 'edbe55a1-a220-4a37-b06f-4e4604dabd1f' for Containers used in Job\n>>>   2022/12/02 03:33:04 Add parent cgroup 'edbe55a1-a220-4a37-b06f-4e4604dabd1f' to container 'edbe55a1-a220-4a37-b06f-4e4604dabd1f'\n>>>   2022/12/02 03:33:04 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n>>>   2022/12/02 03:33:04 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,edbe55a1-a220-4a37-b06f-4e4604dabd1f,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/certs:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,6618m,-v,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/config/.batchai.envlist,--cgroup-parent=/edbe55a1-a220-4a37-b06f-4e4604dabd1f/,--shm-size,2g\n>>>   2022/12/02 03:33:04 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n>>>   2022/12/02 03:33:04 the binding /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f \n>>>   2022/12/02 03:33:04 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,edbe55a1-a220-4a37-b06f-4e4604dabd1f,-m,6618m,-w,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/config/.batchai.envlist,--cgroup-parent=/edbe55a1-a220-4a37-b06f-4e4604dabd1f/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd,-v,/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/certs:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/certs\n>>>   2022/12/02 03:33:04 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name edbe55a1-a220-4a37-b06f-4e4604dabd1f -m 6618m -w /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/config/.batchai.envlist --cgroup-parent=/edbe55a1-a220-4a37-b06f-4e4604dabd1f/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f:/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f -v /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd -v /mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/certs:/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/certs -d -it --privileged --net=host leonamltestc6b7a4af2.azurecr.cn/azureml/azureml_0c7394fe55586ee356098eaded0937ad\n>>>   2022/12/02 03:33:04 Check if container edbe55a1-a220-4a37-b06f-4e4604dabd1f already exist exited with 0, \n>>>   \n>>>   2022/12/02 03:33:04 Check if container edbe55a1-a220-4a37-b06f-4e4604dabd1f already exist exited with 0, \n>>>   \n>>>   2022/12/02 03:33:04 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2022/12/02 03:33:04 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2022/12/02 03:33:04 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-122defeb0379cb60e175edfd018a72c3-4aa69c57ab758d74-01 -sshRequired=false] \n>>>   2022/12/02 03:33:04 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-122defeb0379cb60e175edfd018a72c3-4aa69c57ab758d74-01 -sshRequired=false] \n>>>   2022/12/02 03:33:05 Container ssh is not required for job type.\n>>>   2022/12/02 03:33:05 Starting docker container succeeded.\n>>>   2022/12/02 03:33:05 Starting docker container succeeded.\n>>>   2022/12/02 03:33:05 Disk space after starting docker container: 87994MB\n>>>   2022/12/02 03:33:05 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2022/12/02 03:33:05 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2022/12/02 03:33:05 SidecarEnabled:: sidecar not enabled\n>>>   2022/12/02 03:33:05 Begin execution of runSpecialJobTask\n>>>   2022/12/02 03:33:05 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n>>>   2022/12/02 03:33:05 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs\n>>>   2022/12/02 03:33:05 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs\n>>>   2022/12/02 03:33:05 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/bin/python /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"67990d0e-6989-4285-b64c-24739537aaea\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null,\"SnapshotAssetId\":null}]'\n>>>   2022/12/02 03:33:05 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:33:05 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml_compute_logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n>>>   2022/12/02 03:33:05 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f;/azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/bin/python /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"67990d0e-6989-4285-b64c-24739537aaea\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null,\"SnapshotAssetId\":null}]'\n>>>   2022/12/02 03:33:05 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n>>>   2022/12/02 03:33:05 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-122defeb0379cb60e175edfd018a72c3-4d65f6dbc762f4d7-01 -t edbe55a1-a220-4a37-b06f-4e4604dabd1f bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/761d9093-2720-4fa5-a7f7-e4e14fac148c/job-1/edbe55a1-a220-4a37-b_2acbc068-d945-4115-bff4-be5ec07e388e/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f;/azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/bin/python /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"67990d0e-6989-4285-b64c-24739537aaea\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null,\"SnapshotAssetId\":null}]'\n>>>   2022/12/02 03:33:08 containerName:edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:08 sidecar containerName:edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   2022/12/02 03:33:08 Docker Version that this nodes use are: 20.10.17+azure-1\n>>>   \n>>>   2022/12/02 03:33:08 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:08 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:08 sidecar dockerLauncher:docker\n>>>   2022/12/02 03:33:08 sidecarContainerId:0217863a73579bbf3a96dc7ad4e0b91e8407f98c014468f4eccaf946e16b6d8e\n>>>   2022/12/02 03:33:08 Docker Version that this nodes use are: 20.10.17+azure-1\n>>>   \n>>>   2022/12/02 03:33:08 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:08 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2022/12/02 03:33:08 Docker logs for edbe55a1-a220-4a37-b06f-4e4604dabd1f\n>>>   \n>>>   2022/12/02 03:33:08 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n>>>   \n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:06.088516] Entering job preparation.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.131658] Starting job preparation.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.131697] Extracting the control code.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.131978] Starting extract_project.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.132028] Starting to extract zip file.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.150144] Finished extracting zip file.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.153724] Using urllib.request Python 3.0 or later\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.153764] Start fetching snapshots.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.153800] Start fetching snapshot.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 48\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.583968] Finished fetching snapshot.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.584010] Finished fetching snapshots.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.584020] Finished extract_project.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.584113] Finished fetching and extracting the control code.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.588557] downloadDataStore - Download from datastores if requested.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.589989] Start run_history_prep.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:07.594233] Entering context manager injector.\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: Acquired lockfile /tmp/edbe55a1-a220-4a37-b06f-4e4604dabd1f-datastore.lock to downloading input data references\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:08.271817] downloadDataStore completed\n>>>   2022/12/02 03:33:08 runSpecialJobTask: preparation: [2022-12-02T03:33:08.276892] Job preparation is complete.\n>>>   2022/12/02 03:33:08 DockerSideCarContainerLogs:\n>>>   \n>>>   2022/12/02 03:33:08 DockerSideCarContainerLogs End\n>>>   2022/12/02 03:33:08 Execution of runSpecialJobTask completed\n>>>   2022/12/02 03:33:08 Attempt 1 of http call to https://chinaeast2.api.ml.azure.cn/history/v1.0/private/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/runs/edbe55a1-a220-4a37-b06f-4e4604dabd1f/spans\n>>>   2022/12/02 03:33:08 Process Exiting with Code:  0\n>>>   2022/12/02 03:33:09 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n>>>   \n2022-12-02T03:33:09Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:33:09Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-12-02T03:33:09Z 127.0.0.1 slots=2 max-slots=2\n2022-12-02T03:33:09Z launching Custom job\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2022/12/02 03:33:09 Got JobInfoJson from env\n2022/12/02 03:33:09 Starting App Insight Logger for task:  runTaskLet\n2022/12/02 03:33:09 Version: 3.0.02140.0005 Branch: .SourceBranch Commit: d67fb6d\n2022/12/02 03:33:09 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n2022/12/02 03:33:09 Send process info logs to master server succeeded\n2022/12/02 03:33:09 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n2022/12/02 03:33:09 Send process info logs to master server succeeded\n[2022-12-02T03:33:09.643986] Entering context manager injector.\n[2022-12-02T03:33:10.071551] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['register_deploy.py', '--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder'])\nScript type = None\n[2022-12-02T03:33:10.074948] Entering Run History Context Manager.\n[2022-12-02T03:33:10.962487] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/wd/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f\n[2022-12-02T03:33:10.962701] Preparing to call script [register_deploy.py] with arguments:['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder']\n[2022-12-02T03:33:10.962768] After variable expansion, calling script [register_deploy.py] with arguments:['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder']\n\n/azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nLoading model: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder/sklearn_regression_model.pkl\nLoading conda: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder/conda_dependencies.yml\nLoading score: /mnt/batch/tasks/shared/LS_root/jobs/leonamltestcn/azureml/edbe55a1-a220-4a37-b06f-4e4604dabd1f/mounts/workspaceblobstore/azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder/score.py\nshow yml: \n# Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.8 and later.\n- python=3.8.13\n\n- pip:\n  - azureml-defaults~=1.43.0\n  - inference-schema[numpy-support]\n  - joblib\n  - numpy\n  - scikit-learn==0.22.2.post1\n- pip==20.2.4\nchannels:\n- anaconda\n- conda-forge\n\n/azureml-envs/azureml_8335d832ceca6d919d337aa82ad7ee87/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 0.24.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\nRegistering model test_sklearn_model_pipeline\nEnv is get ready\nstart deploymenttest_sklearn_model_pipeline\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n2022/12/02 03:33:14 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\nRunning\n2022-12-02 03:33:14+00:00 Creating Container Registry if not exists.\n2022-12-02 03:33:14+00:00 Registering the environment.\n2022-12-02 03:33:15+00:00 Use the existing image.\n2022-12-02 03:33:15+00:00 Generating deployment configuration.\n2022-12-02 03:33:16+00:00 Submitting deployment to compute.\n2022-12-02 03:33:17+00:00 Checking the status of deployment mytestpipelinesrv3.\n\nStreaming azureml-logs/75_job_post-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt\n===============================================================================================================\n[2022-12-02T03:33:44.083100] Entering job release\n[2022-12-02T03:33:45.032543] Starting job release\n[2022-12-02T03:33:45.046392] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 168\n[2022-12-02T03:33:45.047386] job release stage : upload_datastore starting...[2022-12-02T03:33:45.047666] job release stage : start importing azureml.history._tracking in run_history_release.\n[2022-12-02T03:33:45.049132] job release stage : copy_batchai_cached_logs starting...\n\n[2022-12-02T03:33:45.051294] job release stage : execute_job_release starting...[2022-12-02T03:33:45.051442] job release stage : copy_batchai_cached_logs completed...\n\n[2022-12-02T03:33:45.076541] Entering context manager injector.\n[2022-12-02T03:33:45.131595] job release stage : upload_datastore completed...\n[2022-12-02T03:33:45.149550] job release stage : send_run_telemetry starting...\n[2022-12-02T03:33:45.172370] get vm size and vm region successfully.\n[2022-12-02T03:33:45.189162] get compute meta data successfully.\n[2022-12-02T03:33:45.311857] post artifact meta request successfully.\n[2022-12-02T03:33:45.367659] upload compute record artifact successfully.\n[2022-12-02T03:33:45.367761] job release stage : send_run_telemetry completed...\n[2022-12-02T03:33:45.390714] job release stage : execute_job_release completed...\n[2022-12-02T03:33:45.391385] Job release is complete\n\nStepRun(Register Model) Execution Summary\n==========================================\nStepRun( Register Model ) Status: Finished\n{'runId': 'edbe55a1-a220-4a37-b06f-4e4604dabd1f', 'target': 'amlcluster', 'status': 'Completed', 'startTimeUtc': '2022-12-02T03:33:02.33928Z', 'endTimeUtc': '2022-12-02T03:33:57.811548Z', 'services': {}, 'properties': {'ContentSnapshotId': '67990d0e-6989-4285-b64c-24739537aaea', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '2b06def4-13ba-4f42-8341-21b847f34dca', 'azureml.moduleName': 'Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '421749f1', 'azureml.pipelinerunid': 'e6c20870-5483-49cb-a39b-5601ed72ebd1', 'azureml.pipeline': 'e6c20870-5483-49cb-a39b-5601ed72ebd1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_deploy.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_release_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'amlcluster', 'dataReferences': {'model_release_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/0a418f9c-9f01-4caf-a82a-d9de4723d533/model_release_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment testparam-model-release-pipeline Environment', 'version': 'Autosave_2022-12-02T03:04:13Z_0aaeb215', 'assetId': 'azureml://locations/chinaeast2/workspaces/68554b4b-1bce-4ce3-85ea-55afaf22fe5f/environments/Experiment testparam-model-release-pipeline Environment/versions/Autosave_2022-12-02T03:04:13Z_0aaeb215', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.8.13', {'pip': ['azureml-sdk~=1.34.0']}, 'scikit-learn', 'pandas'], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs/55_azureml-execution-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt?sv=2019-07-07&sr=b&sig=FvludGROXotfgrKipxnQXXNhonC7hyP8QDZ7ha0Iq18%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'azureml-logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs/65_job_prep-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt?sv=2019-07-07&sr=b&sig=zfwCOF4D8Q%2BpY7HEM88IUFXz%2F0GcdT%2FcxrSioDalTx8%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=j%2FCl7%2Fe6hNXUB46Ih7qskvbzJ0YPux8KM%2BQaQqMBeMs%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'azureml-logs/75_job_post-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs/75_job_post-tvmps_3b63de77aeb24fe9dd894ab12eef23d19f60dee55488f36f2d63518a0a5067c7_d.txt?sv=2019-07-07&sr=b&sig=FFT7JcuK3JCObVMqG7pzFitHgpoIhivfMZuAw960H6I%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'azureml-logs/process_info.json': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=EBChTrb%2FNUwsGMug1rVsmkD7GoRQ0oU6FgNxuPzH4nc%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'azureml-logs/process_status.json': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=aSZ75de061ektb%2FRspldj43k9i9xxb1nerbgJrfB0WI%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'logs/azureml/107_azureml.log': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/107_azureml.log?sv=2019-07-07&sr=b&sig=%2FIZObCSkjmGi3c73K1SjzCbzue7%2B4Zt18QqRwDxTZBs%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A32Z&ske=2022-12-03T11%3A04%3A32Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=td7scQQPYxuPV7yD%2Fm2LSv6tYxlW5CXc6%2BwJ6ha1K%2B4%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A32Z&ske=2022-12-03T11%3A04%3A32Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=uoqbMC%2B5DMVQM8oixFtinEUcDh6rLTQTnANWZu7JbkA%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A32Z&ske=2022-12-03T11%3A04%3A32Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=wu3jSiLM1wReYCrohB3HxvSn%2BgvRZYqN4SMPPFfQcvw%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A32Z&ske=2022-12-03T11%3A04%3A32Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=S02Xd3sn0XC8oSFN%2FxNoezojly9TMpqv8%2FDyaHois4c%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A32Z&ske=2022-12-03T11%3A04%3A32Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.edbe55a1-a220-4a37-b06f-4e4604dabd1f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=csfaRdnzcPjrhgDov2j5Srbfn02NjJSFAz7bIR9RAV8%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A32Z&ske=2022-12-03T11%3A04%3A32Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A23%3A50Z&se=2022-12-02T11%3A33%3A50Z&sp=r'}, 'submittedBy': 'leliang'}\n\n\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': 'e6c20870-5483-49cb-a39b-5601ed72ebd1', 'status': 'Completed', 'startTimeUtc': '2022-12-02T03:32:10.722938Z', 'endTimeUtc': '2022-12-02T03:33:58.824116Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"config_pipeline_arg\":\"https://raw.githubusercontent.com/leonlj/mlopstmptest/main/parameters.json\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2022-12-02T03:32:11.2112353+00:00\",\"EndTime\":\"2022-12-02T03:33:58.7427087+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.e6c20870-5483-49cb-a39b-5601ed72ebd1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=VsRBpvfC3TEH9OTTRhYHLkxZNlpmdwmcFexatI%2FECPY%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A31Z&se=2022-12-02T11%3A32%3A31Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.e6c20870-5483-49cb-a39b-5601ed72ebd1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=s1SNUeM%2BFwDUAnoZ2j6Y5YfVik1o4aDS6fXqtbL2hSE%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A31Z&se=2022-12-02T11%3A32%3A31Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.e6c20870-5483-49cb-a39b-5601ed72ebd1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=zqwYNrbgR9ri1oVN4FGfBMBediNWxCUUXMJ0nno1imA%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T03%3A22%3A31Z&se=2022-12-02T11%3A32%3A31Z&sp=r'}, 'submittedBy': 'leliang'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 123,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 123,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669952041265
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run published pipeline\r\n",
        "**Publish the pipeline**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline.publish(name=\"Mode_Release_Pipeline\", description=\"Use Pipeline for model release\", continue_on_step_failure=True)\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 124,
          "data": {
            "text/plain": "Pipeline(Name: Mode_Release_Pipeline,\nId: b963a087-2d67-4237-9b35-6c269f222fb5,\nStatus: Active,\nEndpoint: https://chinaeast2.api.ml.azure.cn/pipelines/v1.0/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/PipelineRuns/PipelineSubmit/b963a087-2d67-4237-9b35-6c269f222fb5)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Mode_Release_Pipeline</td><td><a href=\"https://studio.ml.azure.cn/pipelines/b963a087-2d67-4237-9b35-6c269f222fb5?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn\" target=\"_blank\" rel=\"noopener\">b963a087-2d67-4237-9b35-6c269f222fb5</a></td><td>Active</td><td><a href=\"https://chinaeast2.api.ml.azure.cn/pipelines/v1.0/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/PipelineRuns/PipelineSubmit/b963a087-2d67-4237-9b35-6c269f222fb5\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 124,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669961745806
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get published pipeline\r\n",
        "\r\n",
        "You can get the published pipeline using **pipeline id**.\r\n",
        "\r\n",
        "To get all the published pipelines for a given workspace(ws): \r\n",
        "```css\r\n",
        "all_pub_pipelines = PublishedPipeline.get_all(ws)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PublishedPipeline\r\n",
        "\r\n",
        "pipeline_id = published_pipeline.id # use your published pipeline id\r\n",
        "published_pipeline = PublishedPipeline.get(ws, pipeline_id)\r\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 125,
          "data": {
            "text/plain": "Pipeline(Name: Mode_Release_Pipeline,\nId: b963a087-2d67-4237-9b35-6c269f222fb5,\nStatus: Active,\nEndpoint: https://chinaeast2.api.ml.azure.cn/pipelines/v1.0/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/PipelineRuns/PipelineSubmit/b963a087-2d67-4237-9b35-6c269f222fb5)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Mode_Release_Pipeline</td><td><a href=\"https://studio.ml.azure.cn/pipelines/b963a087-2d67-4237-9b35-6c269f222fb5?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn\" target=\"_blank\" rel=\"noopener\">b963a087-2d67-4237-9b35-6c269f222fb5</a></td><td>Active</td><td><a href=\"https://chinaeast2.api.ml.azure.cn/pipelines/v1.0/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/PipelineRuns/PipelineSubmit/b963a087-2d67-4237-9b35-6c269f222fb5\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 125,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669961825825
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run published pipeline using its REST endpoint\r\n",
        "[This notebook](https://aka.ms/pl-restep-auth) shows how to authenticate to AML workspace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
        "import requests\r\n",
        "\r\n",
        "auth = InteractiveLoginAuthentication()\r\n",
        "aad_token = auth.get_authentication_header()\r\n",
        "\r\n",
        "rest_endpoint1 = published_pipeline.endpoint\r\n",
        "\r\n",
        "print(\"You can perform HTTP POST on URL {} to trigger this pipeline\".format(rest_endpoint1))\r\n",
        "\r\n",
        "# specify the param when running the pipeline\r\n",
        "response = requests.post(rest_endpoint1, \r\n",
        "                         headers=aad_token, \r\n",
        "                         json={\"ExperimentName\": \"My_Pipeline1\",\r\n",
        "                               \"RunSource\": \"SDK\",\r\n",
        "                               \"ParameterAssignments\": {\"config_pipeline_arg\": config_file}})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can perform HTTP POST on URL https://chinaeast2.api.ml.azure.cn/pipelines/v1.0/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourceGroups/leonamljci/providers/Microsoft.MachineLearningServices/workspaces/leonamltestcn/PipelineRuns/PipelineSubmit/b963a087-2d67-4237-9b35-6c269f222fb5 to trigger this pipeline\n"
        }
      ],
      "execution_count": 126,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669962841804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\r\n",
        "    response.raise_for_status()\r\n",
        "except Exception as ex:    \r\n",
        "    raise Exception('Received bad response from the endpoint: {}\\n'\r\n",
        "                    'Response Code: {}\\n'\r\n",
        "                    'Headers: {}\\n'\r\n",
        "                    'Content: {}'.format(rest_endpoint1, response.status_code, response.headers, response.content)) from ex\r\n",
        "\r\n",
        "run_id = response.json().get('Id')\r\n",
        "print('Submitted pipeline run: ', run_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitted pipeline run:  1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d\n"
        }
      ],
      "execution_count": 127,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669962853984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineRun\r\n",
        "published_pipeline_run_via_rest = PipelineRun(ws.experiments[\"My_Pipeline1\"], run_id)\r\n",
        "RunDetails(published_pipeline_run_via_rest).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8c6fd116db4c4fbe44ea64f4c6c2da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://studio.ml.azure.cn/runs/1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\", \"run_id\": \"1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d\", \"run_properties\": {\"run_id\": \"1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d\", \"created_utc\": \"2022-12-02T06:34:01.322927Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"HTTP\", \"azureml.parameters\": \"{\\\"config_pipeline_arg\\\":\\\"https://raw.githubusercontent.com/leonlj/mlopstmptest/main/parameters.json\\\"}\", \"azureml.continue_on_step_failure\": \"True\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineid\": \"b963a087-2d67-4237-9b35-6c269f222fb5\", \"azureml.pipelineComponent\": \"pipelinerun\", \"azureml.pipelines.stages\": \"{\\\"Initialization\\\":null,\\\"Execution\\\":{\\\"StartTime\\\":\\\"2022-12-02T06:34:02.6054373+00:00\\\",\\\"EndTime\\\":\\\"2022-12-02T06:34:03.5554204+00:00\\\",\\\"Status\\\":\\\"Finished\\\"}}\"}, \"tags\": {}, \"end_time_utc\": \"2022-12-02T06:34:03.644159Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=sLGdsyZpe0UQf8axkOgF0hdLs8sVs0O0vEJ3PqEJZLs%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T07%3A04%3A09Z&se=2022-12-02T15%3A14%3A09Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ruQX%2FbG8K5KwFGxcxd%2BR8DXRgtfx0b53XjIlBvYeFuU%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T07%3A04%3A09Z&se=2022-12-02T15%3A14%3A09Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=03Ow1JiIPl1mqF%2BPeysCX%2B60%2FfBGM%2FldWY79cm5VDlM%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T03%3A15%3A42Z&ske=2022-12-03T11%3A25%3A42Z&sks=b&skv=2019-07-07&st=2022-12-02T07%3A04%3A09Z&se=2022-12-02T15%3A14%3A09Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:00:02\", \"run_number\": \"1669962841\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"46783ec3-9402-4506-b3f7-e501a38c1f7a\", \"name\": \"prepare\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T06:34:02.751518Z\", \"created_time\": \"2022-12-02T06:34:02.751518Z\", \"end_time\": \"2022-12-02T06:34:02.853362Z\", \"duration\": \"0:00:00\", \"run_number\": 1669962842, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T06:34:02.751518Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"0780128b-06aa-4dd7-80d7-2bac665d556c\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T06:34:03.215211Z\", \"created_time\": \"2022-12-02T06:34:03.215211Z\", \"end_time\": \"2022-12-02T06:34:03.287909Z\", \"duration\": \"0:00:00\", \"run_number\": 1669962843, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T06:34:03.215211Z\", \"is_reused\": \"Yes\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-12-02 06:34:02Z] Completing processing run id 46783ec3-9402-4506-b3f7-e501a38c1f7a.\\n[2022-12-02 06:34:03Z] Completing processing run id 0780128b-06aa-4dd7-80d7-2bac665d556c.\\n[2022-12-02 06:34:03Z] Finishing experiment: no runs left and nothing to schedule.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"3300efcc\": {\"node_id\": \"3300efcc\", \"name\": \"prepare\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"46783ec3-9402-4506-b3f7-e501a38c1f7a\"}, \"421749f1\": {\"node_id\": \"421749f1\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"0780128b-06aa-4dd7-80d7-2bac665d556c\"}}, \"edges\": [{\"source_node_id\": \"3300efcc\", \"source_node_name\": \"prepare\", \"source_name\": \"model_release_folder\", \"target_name\": \"model_release_folder\", \"dst_node_id\": \"421749f1\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"46783ec3-9402-4506-b3f7-e501a38c1f7a\", \"name\": \"prepare\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T06:34:02.751518Z\", \"created_time\": \"2022-12-02T06:34:02.751518Z\", \"end_time\": \"2022-12-02T06:34:02.853362Z\", \"duration\": \"0:00:00\", \"run_number\": 1669962842, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T06:34:02.751518Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"0780128b-06aa-4dd7-80d7-2bac665d556c\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-12-02T06:34:03.215211Z\", \"created_time\": \"2022-12-02T06:34:03.215211Z\", \"end_time\": \"2022-12-02T06:34:03.287909Z\", \"duration\": \"0:00:00\", \"run_number\": 1669962843, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-12-02T06:34:03.215211Z\", \"is_reused\": \"Yes\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 128,
      "metadata": {
        "gather": {
          "logged": 1669963637884
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline_run_via_rest.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d\nLink to Azure Machine Learning Portal: https://studio.ml.azure.cn/runs/1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d?wsid=/subscriptions/f7ccde76-13d3-4104-a67c-a396e59e872b/resourcegroups/leonamljci/workspaces/leonamltestcn&tid=fb79b746-da69-43ae-8666-e506470b969c\n\nPipelineRun Execution Summary\n==============================\nPipelineRun Status: Finished\n{'runId': '1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d', 'status': 'Completed', 'startTimeUtc': '2022-12-02T06:34:02.233731Z', 'endTimeUtc': '2022-12-02T06:34:03.644159Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'HTTP', 'azureml.parameters': '{\"config_pipeline_arg\":\"https://raw.githubusercontent.com/leonlj/mlopstmptest/main/parameters.json\"}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineid': 'b963a087-2d67-4237-9b35-6c269f222fb5', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2022-12-02T06:34:02.6054373+00:00\",\"EndTime\":\"2022-12-02T06:34:03.5554204+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=HIms0abMpihprk26sEiK47L%2FB5K%2FXq8JF%2B9YGFqweqg%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T06%3A37%3A17Z&se=2022-12-02T14%3A47%3A17Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=LTiPJTB5fMF1eT%2Fw9JWBzCI7sjtK%2BL7r5MLkS7PGg%2Fs%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T06%3A37%3A17Z&se=2022-12-02T14%3A47%3A17Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://leonamltestcn4641503574.blob.core.chinacloudapi.cn/azureml/ExperimentRun/dcid.1d6b6f63-c4ab-4312-acd5-db1eb2fa7d4d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=5JT5Yr%2BjZiPiXd3B8DE5Hc%2BA2cMRcHTyIqJE3x8Gli8%3D&skoid=9d84ae46-38da-48d8-be48-65495d2ea9b1&sktid=fb79b746-da69-43ae-8666-e506470b969c&skt=2022-12-02T02%3A54%3A12Z&ske=2022-12-03T11%3A04%3A12Z&sks=b&skv=2019-07-07&st=2022-12-02T06%3A37%3A17Z&se=2022-12-02T14%3A47%3A17Z&sp=r'}, 'submittedBy': 'leliang'}\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 129,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 129,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669963645265
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}